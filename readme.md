# ç¯å¢ƒ

## Gello

ç›´æ¥æ‹·è´ç”µè„‘ä¸Šçš„gelloæ–‡ä»¶å¤¹å³å¯

æ³¨æ„ä¿®æ”¹ deploy è„šæœ¬ä¸­çš„ gello è·¯å¾„


## dockerä½¿ç”¨è„šæœ¬

åœ¨Robotwiné¡¹ç›®æ ¹ç›®å½•ä¸‹



åˆ›å»º&è¿›å…¥å®¹å™¨

```bash
./script/_run_robotwin.sh dp3
# ./script/_run_robotwin.sh {policy_name}
```



åˆ é™¤å®¹å™¨

```bash
./script/_delete_docker.sh
```




# DP3

åœ¨A6000ä¸Šå¤ç°Robotwinçš„DP3

[robotwin DP3 ç”¨æˆ·æ‰‹å†Œ](https://robotwin-platform.github.io/doc/usage/DP3.html)



policy è·¯å¾„å‚è€ƒå¦‚ä¸‹ï¼š

![](images/image-11.png)



## dp3ç¯å¢ƒ

åˆ›å»ºå®¹å™¨

```bash
./script/_run_robotwin.sh dp3
```

```bash
blzou@rcvlab-A6000x4-0:/data/blzou/project/RoboTwin$ ./script/_run_robotwin.sh 
ğŸ†• Create new container 'robotwin_dp3' 
7396733d0778b34717a8017e91cbf33e38fab6a9e41c7d7e6a4513bb3448700d
âœ… Container created and patched, waiting for startup...
ğŸšª Entering container robotwin_dp3 ...
root@rcvlab-A6000x4-0:/workspace# 
```



å®‰è£… dp3 ç¯å¢ƒ

```bash
cd policy/DP3/3D-Diffusion-Policy && pip install -e . && cd ..
pip install zarr==2.12.0 wandb ipdb gpustat dm_control omegaconf hydra-core==1.2.0 dill==0.3.5.1 einops==0.4.1 diffusers==0.11.1 numba==0.56.4 moviepy imageio av matplotlib termcolor
```



## æ•°æ®é›†è½¬æ¢ï¼ˆå®˜æ–¹

> [ Robotwin](https://ccnk2vb1cc5g.feishu.cn/wiki/YddcwRUhTirCMQk9T8Yc4KiynFd#share-D5Y3dRjrWogn5ZxK0fIclnLhnyf)éœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶

```bash
bash process_data.sh beat_block_hammer demo_clean 5
# bash process_data.sh ${task_name} ${task_config} ${expert_data_num}
```

`expert_data_num` å‚æ•°æŒ‡å®šè¦ç”¨ä½œè®­ç»ƒæ•°æ®çš„è½¨è¿¹æ•°



## æ•°æ®é›†è½¬æ¢ï¼ˆæˆ‘ä»¬è‡ªå·±çš„çœŸæœºæ•°æ® pkl

> åŒ…å«ç‚¹äº‘çš„æ•°æ®
>
> éœ€è¦ä¿®æ”¹å†…å‚å’Œscal

æ•°æ®é›†éœ€è¦æ”¾åœ¨ `/data2/blzou/dataset/robotwin/data_real`

æ•°æ®é›†æ“ä½œè·¯å¾„æ˜¯åœ¨dockeré‡Œçš„ `/workspace/data_real` ä¸‹çš„ scripts

çœŸæœºé‡‡é›†æ•°æ® .pkl è½¬æ¢ä¸º Robotwinæ ¼å¼çš„ .hdf5 æ–‡ä»¶

```bash
# python pkl_to_hdf5_folder_pc.py --pkl_dir /path/to/pkls --out_dir /path/to/h5s
python ./scripts/pkl_to_hdf5_folder_pc.py --pkl_dir /workspace/data_real/move_banana_to_box_pkl --out_dir /workspace/data_real/move_banana_to_box_dp3/demo_clean/data
```

> è¾“å‡ºæ ¼å¼ï¼š--out\_dir  task/demo\_clean/data/

> æ·»åŠ äº† --binarize\_gripper çš„å¤¹çˆªäºŒå€¼åŒ–å‚æ•°

```bash
(RoboTwin) blzou@rcvlab-A6000x4-0:/data2/blzou/dataset/robotwin/data_real$ python ./scripts/pkl_to_hdf5_folder_pc.py --pkl_dir move_banana_to_box1030 --out_dir move_banana_to_box_dp3/demo_clean/data --binarize_gripper
```





.hdf5 è½¬æˆ .zarr

```bash
bash process_data_franka.sh move_banana_to_box_dp3 demo_clean 1
# bash process_data_franka ${task_name} ${task_config} ${expert_data_num}
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# bash process_data_franka move_banana_to_box_dp3 demo_clean 1
processing episode: 1 / 1
```

ä¿å­˜åœ¨`/workspace/policy/DP3/data`ç›®å½•ä¸‹







## è®­ç»ƒ

> [ Robotwin](https://ccnk2vb1cc5g.feishu.cn/wiki/YddcwRUhTirCMQk9T8Yc4KiynFd#share-N8V4diB1IoPApwxKbMccFsDtntb)æ³¨æ„ä¿®æ”¹



å¼€å§‹è®­ç»ƒ

```bash
bash train.sh beat_block_hammer demo_randomized 5 0 0
# bash train.sh ${task_name} ${task_config} ${expert_data_num} ${seed} ${gpu_id}
# bash train.sh move_banana_to_box_dp3 demo_clean 30 0 3
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# bash train.sh move_banana_to_box_dp3 demo_clean 30 0 3
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹å°†è®­ç»ƒ 3000 æ­¥ï¼Œå¯åœ¨

`/workspace/policy/DP3/3D-Diffusion-Policy/diffusion_policy_3d/config/robot_dp3.yaml`ä¸­ä¿®æ”¹ num\_epochs å’Œ checkpoint\_every



å¼€å§‹è®­ç»ƒï¼ˆä»¥rgbä¸ºä¾‹

```bash
bash train_rgb.sh move_banana_to_box_dp3 demo_clean 1 0 1
# bash train_rgb.sh ${task_name} ${task_config} ${expert_data_num} ${seed} ${gpu_id}
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# bash train_rgb.sh move_banana_to_box_dp3 demo_clean 1 0 1
gpu id (to use): 1
Train mode
/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'robot_dp3.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
[DP3Encoder] point cloud shape: [1024, 6]
[DP3Encoder] state shape: [8]
[DP3Encoder] imagination point shape: None
pointnet use_layernorm: True
pointnet use_final_norm: layernorm
[DP3Encoder] output dim: 192
[DiffusionUnetHybridPointcloudPolicy] use_pc_color: True
[DiffusionUnetHybridPointcloudPolicy] pointnet_type: pointnet
[2025-10-10 05:20:17,652][diffusion_policy_3d.model.diffusion.conditional_unet1d][INFO] - number of parameters: 2.623302e+08
----------------------------------
Class name: DP3
  Number of parameters: 262.5751M
   _dummy_variable: 0.0000M (0.00%)
   obs_encoder: 0.2449M (0.09%)
   model: 262.3302M (99.91%)
   mask_generator: 0.0000M (0.00%)
----------------------------------
Replay Buffer: state, shape (333, 8), dtype float32, range -2.49~2.29
Replay Buffer: action, shape (333, 8), dtype float32, range -2.49~2.29
Replay Buffer: point_cloud, shape (333, 1024, 6), dtype float32, range -7.18~30.00
--------------------------
-----------------------------
[WandB] group: move_banana_to_box_dp3-robot_dp3-train
[WandB] name: move_banana_to_box_dp3-demo_clean-1
-----------------------------
Training epoch 63:   0%|                                                                                                                                                                                                                                  | 0/2 [00:00<?, ?it/s]
saved in  checkpoints/move_banana_to_box_dp3-demo_clean-1_w_rgb_0/500.ckpt
```



## è¯„ä¼°

```bash
bash eval.sh beat_block_hammer demo_clean demo_clean 5 0 0
# bash eval.sh ${task_name} ${task_config} ${ckpt_setting} ${expert_data_num} ${seed} ${gpu_id}
```

`task_config` å­—æ®µæŒ‡çš„æ˜¯è¯„ä¼°ç¯å¢ƒé…ç½®ï¼Œè€Œ `ckpt_setting` å­—æ®µæŒ‡çš„æ˜¯ç­–ç•¥å­¦ä¹ æœŸé—´ä½¿ç”¨çš„è®­ç»ƒæ•°æ®é…ç½®

è¿è¡Œç»“æœä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `eval_result` æ–‡ä»¶å¤¹



> âš ï¸å¦‚æœéœ€è¦RGBçš„è¯ï¼Œinferéœ€è¦ä»¥ä¸‹é…ç½®æ–‡ä»¶çš„ä¿®æ”¹

* `policy/DP3/deploy_policy.yml`

![](images/image-8.png)

ä½¿ç”¨rgb





## éƒ¨ç½²

ä¿®æ”¹ gello çš„è·¯å¾„

åœ¨ `deploy_policy_real.py` æ–‡ä»¶ä¸­

```python
sys.path.append('/workspace/third_party/gello_software_bp')
```



> éœ€è¦æ³¨æ„ï¼Œfrankaé‡‡é›†åˆ°çš„æ•°æ®çš„joint\_positionså’Œjoint\_velocitiesæ˜¯ä¸€æ ·çš„ï¼Œè€Œä¸”éƒ½æ˜¯åŒ…å«gripperçš„
>
> ä¹Ÿå°±æ˜¯è¯´éƒ½æ˜¯ 8 ç»´çš„

```bash
python deploy_policy_real.py 
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# python deploy_policy_real.py 
```



# RDT

rdt è·¯å¾„å‚è€ƒå¦‚ä¸‹ï¼š

![](images/image-10.png)



## rdtç¯å¢ƒ

åˆ›å»ºå¹¶è¿è¡Œå®¹å™¨

```bash
./script/_run_robotwin.sh 
```

```bash
blzou@rcvlab-A6000x4-0:/data/blzou/project/RoboTwin$ ./script/_run_robotwin.sh rdt
ğŸ†• Create new container 'robotwin_rdt' 
7396733d0778b34717a8017e91cbf33e38fab6a9e41c7d7e6a4513bb3448700d
âœ… Container created and patched, waiting for startup...
ğŸšª Entering container robotwin_rdt...
root@rcvlab-A6000x4-0:/workspace# 
```



Pip ç¯å¢ƒ

```bash
# Install pytorch
# Look up https://pytorch.org/get-started/previous-versions/ with your cuda version for a correct command
pip install torch==2.1.0 torchvision==0.16.0  --index-url https://download.pytorch.org/whl/cu121

# Install packaging
pip install packaging==24.0
pip install ninja
# Verify Ninja --> should return exit code "0"
ninja --version; echo $?
# Install flash-attn
pip install flash-attn==2.7.2.post1 --no-build-isolation

# Install other prequisites
pip install -r requirements.txt
# If you are using a PyPI mirror, you may encounter issues when downloading tfds-nightly and tensorflow. 
# Please use the official source to download these packages.
# pip install tfds-nightly==4.9.4.dev202402070044 -i  https://pypi.org/simple
# pip install tensorflow==2.15.0.post1 -i  https://pypi.org/simple
```



ä¸‹è½½æ¨¡å‹

```bash
# In the ROOT directory
cd policy 
mkdir weights
cd weights
mkdir RDT && cd RDT
# Download the models used by RDT
huggingface-cli download google/t5-v1_1-xxl --local-dir t5-v1_1-xxl
huggingface-cli download google/siglip-so400m-patch14-384 --local-dir siglip-so400m-patch14-384
huggingface-cli download robotics-diffusion-transformer/rdt-1b --local-dir rdt-1b
```

> æ¨¡å‹ä¿å­˜çš„è·¯å¾„åœ¨æœåŠ¡å™¨çš„`/data2/blzou/dataset/robotwin/ckpt/weights`
>
> åœ¨å®¹å™¨çš„`/workspace/ckpt/weights`



## æ•°æ®é›†è½¬æ¢ï¼ˆours

æ•°æ®é›†éœ€è¦æ”¾åœ¨ `/data2/blzou/dataset/robotwin/data_real`

è·¯å¾„æ˜¯åœ¨dockeré‡Œçš„ `/workspace/data_real` ä¸‹çš„ scripts

.pkl è½¬ .hdf5

```bash
python pkl_to_hdf5_folder_resize.py --pkl_dir /path/to/pkls --out_dir /path/to/h5s
# python scripts/pkl_to_hdf5_folder_resize.py --pkl_dir ./move_banana_to_box1030_compress --out_dir move_banana_to_box_rdt/demo_clean/data --binarize_gripper
```

```bash
(RoboTwin) blzou@rcvlab-A6000x4-0:/data2/blzou/dataset/robotwin/data_real$ python scripts/pkl_to_hdf5_folder_resize.py --pkl_dir ./move_banana_to_box1030_compress --out_dir move_banana_to_box_rdt/demo_clean/data --binarize_gripper
```

> è¾“å‡ºæ ¼å¼ï¼š--out\_dir  task/demo\_clean/data/
>
> åŒæ ·æœ‰å¤¹çˆªäºŒå€¼åŒ–é€‰é¡¹



æˆ‘ä»¬çš„æ•°æ®é›†h5æ ¼å¼

```bash
ğŸ” Inspecting HDF5 file: ./move_banana_to_box/demo_clean/data/0.hdf5
============================================================
Dataset: endpose/ee_pos_quat
  Shape: (334, 7)
  Dtype: float64
--------------------------------------------------
Dataset: endpose/gripper
  Shape: (334,)
  Dtype: float32
--------------------------------------------------
Dataset: joint_action/gripper
  Shape: (334,)
  Dtype: float32
--------------------------------------------------
Dataset: joint_action/positions
  Shape: (334, 7)
  Dtype: float32
--------------------------------------------------
Dataset: joint_action/velocities
  Shape: (334, 8)
  Dtype: float32
--------------------------------------------------
Dataset: observation/front_camera/depth_raw
  Shape: (334, 480, 640, 1)
  Dtype: float32
--------------------------------------------------
Dataset: observation/front_camera/rgb
  Shape: (334,)
  Dtype: |S16095
--------------------------------------------------
âœ… Inspection complete.
```



æˆ‘ä»¬çš„ .hdf5 æ”¹æˆ RDT æ‰€éœ€çš„ .hdf5

ä»¥åŠç”Ÿæˆ RDT æ‰€éœ€çš„ instructionsï¼ˆ.pt

> éœ€è¦ä¿®æ”¹ encode model çš„è·¯å¾„
>
> `/workspace/policy/RDT/scripts/encode_lang_batch_once.py`

![](images/image-7.png)

```bash
python ./scripts/generate_instructions.py --task_dir /path/to/h5s
# python ./scripts/generate_instructions.py --task_dir ./move_banana_to_box_rdt/demo_clean
```

```bash
(RoboTwin) blzou@rcvlab-A6000x4-0:/data2/blzou/dataset/robotwin/data_real$ python ./scripts/generate_instructions.py --task_dir ./move_banana_to_box_rdt/demo_clean
```

![](images/image-9.png)



åˆ›å»ºæ–‡ä»¶å¤¹

åœ¨dockerä¸­`/workspace/policy/RDT`ä¸‹ï¼š

```bash
mkdir processed_data && mkdir training_data
```



```bash
bash process_data_franka.sh move_banana_to_box demo_clean 1 3
# bash process_data_franka ${task_name} ${task_config} ${expert_data_num} ${gpu_id}
```

```bash
# root@rcvlab-A6000x4-0:/workspace/policy/RDT# bash process_data_franka.sh move_banana_to_box_rdt demo_clean 30 3
```

ä¿å­˜è·¯å¾„åœ¨`/workspace/policy/RDT/processed_data`ä¸‹

![](images/image-6.png)



## è®­ç»ƒ

ç”Ÿæˆé…ç½®æ–‡ä»¶

> éœ€ä¿®æ”¹é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
>
> `/workspace/policy/RDT/model_config/_generate_model_config.py`

![](images/image-12.png)



`$model_name` ç®¡ç†æ¨¡å‹çš„è®­ç»ƒï¼ŒåŒ…æ‹¬è®­ç»ƒæ•°æ®å’Œè®­ç»ƒé…ç½®

```bash
bash generate.sh ${model_name}
# bash generate.sh RDT_demo_clean
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/RDT# bash generate.sh RDT_demo_clean
```

è¿™å°†åœ¨ training\_data ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º `\${model_name}` çš„æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨ model\_config ä¸‹åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶ `\${model_name}.yml`



è½¬ç§»è®­ç»ƒæ•°æ®

ä» `processed_data` å¤åˆ¶åˆ° `training_data/${model_name}`

`training_data`ç»“æ„ç±»ä¼¼å¦‚ä¸‹ï¼š

```bash
training_data/${model_name}
â”œâ”€â”€ ${task_1}
â”‚   â”œâ”€â”€ episode_0
|   |   |â”€â”€ episode_0.hdf5
|   |   |-- instructions
|   â”‚   â”‚   â”œâ”€â”€ lang_embed_0.pt
|   â”‚   â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ ${task_2}
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ ...
```

![](images/image-5.png)



è®­ç»ƒ

> éœ€ä¿®æ”¹siglip-so400m-patch14-384æ¨¡å‹è·¯å¾„
>
> `policy/RDT/finetune.sh`

![](images/image-4.png)



```bash
bash finetune.sh ${model_name}
# bash finetune.sh RDT_demo_clean
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/RDT# bash finetune.sh RDT_demo_clean
```

ä¸­é€”ä¸­æ–­äº†æ¥ç€è®­ç»ƒå¯ä»¥æŸ¥çœ‹ä¸‹é¢æ–‡æ¡£

[ Frankaï¼ˆRobotwin](https://ccnk2vb1cc5g.feishu.cn/wiki/YddcwRUhTirCMQk9T8Yc4KiynFd#CSbId1N7ToE8wOxg6IacL0FBnuA)



## éƒ¨ç½²

ä¿®æ”¹ gello çš„è·¯å¾„

åœ¨ `deploy_policy_real.py` æ–‡ä»¶ä¸­

```python
sys.path.append('/workspace/third_party/gello_software_bp')
```



```bash
python deploy_policy_real.py 
```

```bash
root@rcvlab-A6000x4-0:/workspace/policy/RDT# python deploy_policy_real.py 
```





# è¸©å‘è®°å½•

## DP3ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®æ—¶ï¼ŒæŠ¥ ZeroDivisionError: division by zero é”™è¯¯

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# bash process_data.sh beat_block_hammer demo_randomized 10
processing episode: 10 / 10
If you get a `ZeroDivisionError: division by zero`, check that `data/pointcloud` in the task config is set to true.
Traceback (most recent call last):
  File "/workspace/policy/DP3/scripts/process_data.py", line 152, in <module>
    main()
  File "/workspace/policy/DP3/scripts/process_data.py", line 114, in main
    zarr_data.create_dataset(
  File "/usr/local/lib/python3.10/dist-packages/zarr/hierarchy.py", line 948, in create_dataset
    return self._write_op(self._create_dataset_nosync, name, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/zarr/hierarchy.py", line 800, in _write_op
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/zarr/hierarchy.py", line 965, in _create_dataset_nosync
    a = array(data, store=self._store, path=path, chunk_store=self._chunk_store,
  File "/usr/local/lib/python3.10/dist-packages/zarr/creation.py", line 380, in array
    z[...] = data
  File "/usr/local/lib/python3.10/dist-packages/zarr/core.py", line 1353, in __setitem__
    self.set_basic_selection(pure_selection, value, fields=fields)
  File "/usr/local/lib/python3.10/dist-packages/zarr/core.py", line 1448, in set_basic_selection
    return self._set_basic_selection_nd(selection, value, fields=fields)
  File "/usr/local/lib/python3.10/dist-packages/zarr/core.py", line 1746, in _set_basic_selection_nd
    indexer = BasicIndexer(selection, self)
  File "/usr/local/lib/python3.10/dist-packages/zarr/indexing.py", line 342, in __init__
    dim_indexer = SliceDimIndexer(dim_sel, dim_len, dim_chunk_len)
  File "/usr/local/lib/python3.10/dist-packages/zarr/indexing.py", line 176, in __init__
    self.nchunks = ceildiv(self.dim_len, self.dim_chunk_len)
  File "/usr/local/lib/python3.10/dist-packages/zarr/indexing.py", line 160, in ceildiv
    return math.ceil(a / b)
ZeroDivisionError: division by zero
```

> åŸå› æ˜¯ ç”±äº **DP3** æ˜¯éœ€è¦ç‚¹äº‘è¾“å…¥çš„ 3D ç­–ç•¥ï¼Œå› æ­¤è¯·ç¡®ä¿åœ¨æ•°æ®é‡‡é›†æ—¶å°† `data_type/pointcloud` è®¾ç½®ä¸º `true`

ä¿®æ”¹ `task_config/demo_randomized.yml`å¯¹åº”çš„é…ç½®æ–‡ä»¶åï¼Œé‡æ–°æ”¶é›†æ•°æ®

```bash
# if you want to modify the config, please check the following tutorial first:
# https://robotwin-platform.github.io/doc/usage/configurations.html
render_freq: 0
episode_num: 10
use_seed: false
save_freq: 15
embodiment: [aloha-agilex]
language_num: 100
domain_randomization:
  random_background: true
  cluttered_table: true
  clean_background_rate: 0.02
  random_head_camera_dis: 0
  random_table_height: 0.03
  random_light: true
  crazy_random_light_rate: 0.02
camera:
  head_camera_type: D435
  wrist_camera_type: D435
  collect_head_camera: true
  collect_wrist_camera: true
data_type:
  rgb: true
  third_view: false
  depth: false
  pointcloud: true
  # pointcloud: false
  observer: false
  endpose: true
  qpos: true
  mesh_segmentation: false
  actor_segmentation: false
pcd_down_sample_num: 1024
pcd_crop: true
save_path: ./data
clear_cache_freq: 5
collect_data: true
eval_video_log: true

```



## DP3ï¼šè®­ç»ƒæ—¶ï¼Œshmå…±äº«å†…å­˜ä¸è¶³æŠ¥é”™

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# bash train.sh beat_block_hammer demo_randomized 5 0 0
gpu id (to use): 0
Train mode
/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'robot_dp3.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
[DP3Encoder] point cloud shape: [1024, 6]
[DP3Encoder] state shape: [14]
[DP3Encoder] imagination point shape: None
[PointNetEncoderXYZ] use_layernorm: True
[PointNetEncoderXYZ] use_final_norm: layernorm
[DP3Encoder] output dim: 192
[DiffusionUnetHybridPointcloudPolicy] use_pc_color: False
[DiffusionUnetHybridPointcloudPolicy] pointnet_type: pointnet
[2025-09-30 07:14:15,403][diffusion_policy_3d.model.diffusion.conditional_unet1d][INFO] - number of parameters: 2.623517e+08
----------------------------------
Class name: DP3
  Number of parameters: 262.4325M
   _dummy_variable: 0.0000M (0.00%)
   obs_encoder: 0.0808M (0.03%)
   model: 262.3517M (99.97%)
   mask_generator: 0.0000M (0.00%)
----------------------------------
Replay Buffer: state, shape (581, 14), dtype float32, range -1.79~2.91
Replay Buffer: action, shape (581, 14), dtype float32, range -1.79~2.91
Replay Buffer: point_cloud, shape (581, 1024, 6), dtype float32, range -0.43~1.20
--------------------------
-----------------------------
[WandB] group: beat_block_hammer-robot_dp3-train
[WandB] name: beat_block_hammer-demo_randomized-5
-----------------------------
Training epoch 0:   0%|                                                        | 0/2 [00:00<?, ?it/s]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
Error executing job with overrides: ['task_name=beat_block_hammer', 'training.debug=False', 'training.seed=0', 'training.device=cuda:0', 'exp_name=beat_block_hammer-robot_dp3-train', 'logging.mode=online', 'checkpoint.save_ckpt=True', 'expert_data_num=5', 'setting=demo_randomized']
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 43288) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 478, in <module>
    main()
  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 474, in main
    workspace.run()
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 192, in run
    for batch_idx, batch in enumerate(tepoch):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1283, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 43288) exited unexpectedly
```

> åŸå› æ˜¯dp3çš„è®­ç»ƒæ•°æ®æ˜¯ç‚¹äº‘ï¼Œå†…å­˜å ç”¨æ¯”è¾ƒå¤§ï¼Œè€Œä¸” Pytorch çš„ dataloader ä½¿ç”¨å¤šè¿›ç¨‹æ—¶ï¼Œä¼šé€šè¿‡ shmä¼ è¾“æ•°æ®ï¼Œdocker å¯åŠ¨å®¹å™¨åï¼Œé»˜è®¤ shm å¤§å°æ˜¯ 64MBï¼Œéœ€è¦è¿›è¡Œæ‰©å¤§

```bash
root@rcvlab-A6000x4-0:/workspace/policy/DP3# df -h /dev/shm
Filesystem      Size  Used Avail Use% Mounted on
shm              64M   35M   30M  55% /dev/shm
```



å¯¹ `_run_robotwin.sh` è¿›è¡Œä¿®æ”¹ï¼Œæ·»åŠ  --shm-size=8g

```bash
docker run -d \
    --name "$CONTAINER_NAME" \
    --gpus all \
    --shm-size=8g \
    --network=host \
    --privileged \
    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics \
    -e CKPT_PATH="$CKPT_PATH" \
    -v "$CURRENT_DIR":/workspace \
    -v "$ASSETS_PATH/assets:/workspace/assets" \
    -v "$ASSETS_PATH/data:/workspace/data" \
    -w /workspace \
    "$IMAGE" \
    bash -c "
        tail -f /dev/null
    "

echo "âœ… Container created and patched, waiting for startup..."
sleep 2
```



## DP3ï¼šè®­ç»ƒæ—¶æŠ¥ state ç»´åº¦é”™è¯¯

```bash
Error executing job with overrides: ['task_name=move_banana_to_box_dp3', 'training.debug=False', 'training.seed=0', 'training.device=cuda:0', 'exp_name=move_banana_to_box_dp3-robot_dp3-train', 'logging.mode=online', 'checkpoint.save_ckpt=True', 'expert_data_num=1', 'setting=demo_clean']
Traceback (most recent call last):
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 478, in <module>
    main()
  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 474, in main
    workspace.run()
  File "/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py", line 201, in run
    raw_loss, loss_dict = self.model.compute_loss(batch)
  File "/workspace/policy/DP3/3D-Diffusion-Policy/diffusion_policy_3d/policy/dp3.py", line 290, in compute_loss
    nobs_features = self.obs_encoder(this_nobs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/policy/DP3/3D-Diffusion-Policy/diffusion_policy_3d/model/vision/pointnet_extractor.py", line 263, in forward
    state_feat = self.state_mlp(state)  # B * 64
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (768x8 and 14x64)
```

> åŸå› æ—¶ state ç»´åº¦ä¸åŒ¹é…ï¼Œå°†ä¸‹å›¾ä¸­çš„ 14 æ”¹æˆ 8 å³å¯

![](images/image-3.png)





## DP3: ckptæ— æ³•æ¥ç€ç»§ç»­è®­ç»ƒ

![](images/image-2.png)

![](images/image-1.png)

> æ— æ³•è¯»å–åˆ°æœ€æ–°çš„ckptæ¥ç€è®­ç»ƒ

> åŸå› æ˜¯æºä»£ç æœ‰é€»è¾‘æœ‰é—®é¢˜ï¼Œéœ€è¦ä¿®æ”¹
>
> `/workspace/policy/DP3/3D-Diffusion-Policy/train_dp3.py`æ–‡ä»¶ä¸­çš„ get\_checkpoint\_path å‡½æ•°

```bash
def get_checkpoint_path(self, tag="latest"):
    checkpoint_dir = pathlib.Path(DP3_ROOT).joinpath(f"checkpoints/{self.cfg.task.name}_{self.cfg.training.seed}")
    if tag == "latest":
        # return pathlib.Path(self.output_dir).joinpath("checkpoints", f"{tag}.ckpt")
        ckpt_files = list(checkpoint_dir.glob("*.ckpt"))
        if not ckpt_files:
            return None
        
        # æŒ‰ä¿®æ”¹æ—¶é—´ï¼ˆmtimeï¼‰é™åºæ’åºï¼Œå–æœ€æ–°çš„
        latest_ckpt = max(ckpt_files, key=lambda f: f.stat().st_mtime)
        return latest_ckpt
    elif tag == "best":
        # the checkpoints are saved as format: epoch={}-test_mean_score={}.ckpt
        # find the best checkpoint
        # checkpoint_dir = pathlib.Path(self.output_dir).joinpath("checkpoints")
        all_checkpoints = os.listdir(checkpoint_dir)
        best_ckpt = None
        best_score = -1e10
        for ckpt in all_checkpoints:
            if "latest" in ckpt:
                continue
            score = float(ckpt.split("test_mean_score=")[1].split(".ckpt")[0])
            if score > best_score:
                best_ckpt = ckpt
                best_score = score
        return pathlib.Path(self.output_dir).joinpath("checkpoints", best_ckpt)
    else:
        raise NotImplementedError(f"tag {tag} not implemented")
```

> å¹¶ä¸”éœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶`/workspace/policy/DP3/3D-Diffusion-Policy/diffusion_policy_3d/config/robot_dp3.yaml`

```bash
...
training:
  ...
  resume: True    # ä¿®æ”¹ä¸ºTrue
```





## DP3: éƒ¨ç½²æ¨ç†è¿‡ç¨‹ä¸­ gripper ä¸ work

```bash
gripper : 0.7045450806617737
gripper : 0.7031018137931824
gripper : 0.7035694718360901
gripper : 0.7058286070823669
gripper : 0.7057570219039917
gripper : 0.705588161945343
gripper : 0.7053167223930359
gripper : 0.7045924663543701
gripper : 0.7048159241676331
gripper : 0.7052463889122009
gripper : 0.7050356268882751
gripper : 0.7038112282752991
gripper : 0.7031931281089783
gripper : 0.7024000287055969
gripper : 0.7028611302375793
gripper : 0.705430805683136
gripper : 0.70560222864151
gripper : 0.7048481702804565
gripper : 0.7041599750518799
gripper : 0.7030879259109497
gripper : 0.7033390998840332
gripper : 0.7063479423522949
gripper : 0.7056357860565186
gripper : 0.7050377726554871
gripper : 0.7037075161933899
gripper : 0.7012830376625061
gripper : 0.6996189951896667
```

> æ‰“å°å‡ºæ¥çš„ gripper å€¼ä¸€ç›´åœ¨ 0.7 å·¦å³
>
> é—®é¢˜æ€è·¯ï¼š
>
> 1. å…ˆä»¥ä¸ºæ˜¯æŠ“å–çš„ç½®ä¿¡åŒºé—´å¤ªå°ï¼Œä½†ç»è¿‡å¤¹çˆªäºŒå€¼åŒ–ä¹‹åï¼Œä¾ç„¶ä¸work
>
> 2. å†ç»™ traj åšæŠ½å¸§åï¼Œè¿åŠ¨ååˆ†ä¸æ»‘ï¼Œgripperä¹ŸæˆåŠŸwork

> åŸå› åˆ†æï¼š
>
> * æŠ½å¸§æ˜¯å·¥ç¨‹ä¸Šçš„ä¼˜åŒ–ï¼Œåœ¨çœŸæœºéƒ¨ç½²ä¸­æœ‰å¾ˆå¤šçš„å™ªå£°ï¼Œå¦‚æœä¸åšæŠ½å¸§ï¼Œé‚£ä¹ˆæ¨¡å‹åœ¨å­¦çš„æ—¶å€™ä¼šæŠŠæ¯ä¸ªç‚¹éƒ½å­¦åˆ°ï¼Œå¯¼è‡´æ”¶æ•›åŸŸæ¯”è¾ƒå¼ºï¼Œæœ€åçš„ç»“æœå°±æ˜¯gripperä¸workï¼Œå› ä¸ºä¸­é—´ä¸€äº›ç‚¹æ²¡åˆ°ä½ï¼Ÿ
>
> * ç®€å•æ¥è¯´å°±æ˜¯ï¼ŒæŠŠæ•´ä¸ªè½¨è¿¹å˜æˆä¸€äº›ç‰¹å®šçš„å…³é”®ç‚¹ï¼Œåªè¦æœºæ¢°è‡‚åˆ°äº†é‚£ä¸ªä½ç½®å³å¯ï¼Œå¤§å¤§æé«˜äº†æˆåŠŸç‡



## RDT: å¤šå¡è®­ç»ƒæŠ¥é”™

```bash
10/14/2025 12:03:50 - INFO - __main__ - Constructing model from pretrained checkpoint.
Diffusion params: 1.228320e+09
Loading weights from local directory
Diffusion params: 1.228320e+09
Loading weights from local directory
/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
10/14/2025 12:04:44 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (32).
[2025-10-14 12:04:44,277] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown
rcvlab-A6000x4-0:223645:223645 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0

rcvlab-A6000x4-0:223645:223645 [0] bootstrap.cc:45 NCCL WARN Bootstrap : no socket interface found
rcvlab-A6000x4-0:223645:223645 [0] NCCL INFO init.cc:82 -> 3
rcvlab-A6000x4-0:223645:223645 [0] NCCL INFO init.cc:101 -> 3
Traceback (most recent call last):
  File "/workspace/policy/RDT/main.py", line 344, in <module>
    train(args, logger)
  File "/workspace/policy/RDT/train/train.py", line 312, in train
    rdt, optimizer, train_dataloader, sample_dataloader, lr_scheduler = (accelerator.prepare(
  File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1284, in prepare
    result = self._prepare_deepspeed(*args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1751, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/__init__.py", line 181, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 262, in __init__
    self._configure_distributed_model(model)
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1157, in _configure_distributed_model
    self._broadcast_model()
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1077, in _broadcast_model
    dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 224, in broadcast
    return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/torch.py", line 199, in broadcast
    return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1910, in broadcast
    work = group.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1249, internal error - please report this issue to the NCCL developers, NCCL version 2.18.5
ncclInternalError: Internal check failed.
Last error:
Bootstrap : no socket interface found
[2025-10-14 12:04:49,079] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 223646 closing signal SIGTERM
[2025-10-14 12:04:49,795] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 223645) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 7, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 46, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1073, in launch_command
    multi_gpu_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 718, in multi_gpu_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-14_12:04:49
  host      : rcvlab-A6000x4-0
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 223645)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
```

```bash
NCCL error ... Bootstrap : no socket interface found
...
ncclInternalError: Internal check failed.
```

> NCCLï¼ˆNVIDIA Collective Communications Libraryï¼‰åœ¨å¤š GPU é€šä¿¡åˆå§‹åŒ–æ—¶å¤±è´¥
>
> æ ¹æœ¬åŸå› æ˜¯ NCCL æ— æ³•æ‰¾åˆ°åˆé€‚çš„ç½‘ç»œæ¥å£ç”¨äºè¿›ç¨‹é—´é€šä¿¡ï¼ˆå³ä½¿åœ¨åŒä¸€å°æœºå™¨ä¸Šï¼‰

æœ€ç»ˆåŸå› æ˜¯ finetune.sh è„šæœ¬é‡Œçš„&#x20;

`export NCCL_SOCKET_IFNAME=eth0` è®¾ç½®ä¸æ­£ç¡®ï¼Œeth0 å¹¶ä¸å­˜åœ¨

ä¿®æ”¹ä¸º

![](images/image.png)

å³å¯



## RDTï¼šckptæ¥ç€è®­ç»ƒæ­¥éª¤

ä¿®æ”¹`/workspace/policy/RDT/finetune.sh`

æ·»åŠ `resume_from_checkpoint`å‚æ•°

> `resume_from_checkpoint`å‚æ•°éœ€è¦çš„æ˜¯ckptçš„æ–‡ä»¶å

```bash
RESUME_FROM_CKPT="checkpoint-7500"

accelerate launch --main_process_port=28499  main.py \
    --deepspeed="./configs/zero2.json" \
    --pretrained_model_name_or_path=$PRETRAINED_MODEL_NAME \
    --pretrained_text_encoder_name_or_path=$TEXT_ENCODER_NAME \
    --pretrained_vision_encoder_name_or_path=$VISION_ENCODER_NAME \
    --output_dir=$OUTPUT_DIR \
    --train_batch_size=$TRAIN_BATCH_SIZE \
    --sample_batch_size=$SAMPLE_BATCH_SIZE \
    --max_train_steps=$MAX_TRAIN_STEPS \
    --checkpointing_period=$CHECKPOINTING_PERIOD \
    --sample_period=$SAMPLE_PERIOD \
    --checkpoints_total_limit=$CHECKPOINTS_TOTAL_LIMIT \
    --lr_scheduler="constant" \
    --learning_rate=$LEARNING_RATE \
    --mixed_precision="bf16" \
    --dataloader_num_workers=$DATALOADER_NUM_WORKERS \
    --image_aug \
    --dataset_type="finetune" \
    --state_noise_snr=$STATE_NOISE_SNR \
    --load_from_hdf5 \
    --report_to=wandb \
    --precomp_lang_embed \
    --gradient_accumulation_steps=$GRAD_ACCUM_STEPS \
    --resume_from_checkpoint=$RESUME_FROM_CKPT \    # æ·»åŠ 
    --model_config_path=$CONFIG_FILE \
    --CONFIG_NAME=$CONFIG_NAME
```
